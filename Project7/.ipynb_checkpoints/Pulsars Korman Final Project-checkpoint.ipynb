{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset from: https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star\n",
    "df = pd.read_csv('data/pulsar_stars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no NaN data\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily skewed toward negative class\n",
    "df['target_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disconcerting that multiple factors weigh heavily on target class\n",
    "corr['target_class'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(40,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM WITH PROPORTIONING DATASET\n",
    "\n",
    "\n",
    "# startified split to make test set labeled evenly\n",
    "# maintains proportionality of dataset\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# for train_index, test_index in split.split(df, df['target_class']):\n",
    "#     train_set = df.loc[train_index]\n",
    "#     test_set = df.loc[test_index]\n",
    "\n",
    "# train_set['target_class'].value_counts()\n",
    "\n",
    "# #split into train 1s and 0s\n",
    "# pos_train = train_set.loc[train_set['target_class'] == 1]\n",
    "# neg_train = train_set.loc[train_set['target_class'] == 0]\n",
    "# pos_test = test_set.loc[test_set['target_class'] == 1]\n",
    "# neg_test = test_set.loc[test_set['target_class'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split into train 1s and 0s\n",
    "pos = df.loc[df['target_class'] == 1]\n",
    "neg = df.loc[df['target_class'] == 0]\n",
    "\n",
    "threeXpos = round(pos.shape[0]*2.5)\n",
    "# if I wanted to take a random batch of the negative class\n",
    "# neg_batch_seed = np.random.randint(0, (neg.shape[0] - threeXpos))\n",
    "\n",
    "#3 to l neg. to pos.\n",
    "proportioned_neg = neg[0:threeXpos]\n",
    "#train\n",
    "neg_test = neg[threeXpos:]\n",
    "print(neg_test.shape)\n",
    "\n",
    "pos = pos.append(proportioned_neg)\n",
    "\n",
    "pos['target_class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df into an array\n",
    "array = pos.values\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will append to testing set\n",
    "neg_test = neg_test.values\n",
    "neg_testX = neg_test[:, :8]\n",
    "neg_testY = neg_test[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize input values between 0 and 1\n",
    "def normalize(array):\n",
    "    for column in range(array.shape[1]):\n",
    "        array[:,column] = (array[:,column] - np.min(array[:,column])) / (np.max(array[:,column]) - np.min(array[:,column]))\n",
    "    return array                                \n",
    "                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = array[:, :8] # X values... already column vectors\n",
    "X_s = normalize(X_s)\n",
    "\n",
    "print(X_s.shape)\n",
    "y_s = array[:, 8] # labels\n",
    "y_s.astype(int) # convert to integers\n",
    "\n",
    "print(y_s.shape)\n",
    "print('_________')\n",
    "\n",
    "# shuffle - then split into train and test sets\n",
    "rnd_inds = np.arange(len(X_s)) #array xs long\n",
    "np.random.shuffle(rnd_inds) # xs shuffled\n",
    "\n",
    "# reorder xs and corresponding ys\n",
    "X_s = X_s[rnd_inds,:] \n",
    "y_s = y_s[rnd_inds] \n",
    "\n",
    "\n",
    "#STRATIFIED SAMPLING, GET EQUAL AMT OF ONES AND ZEROS... SKLEARN\n",
    "\n",
    "\n",
    "\n",
    "# 85% of dataset put into training set\n",
    "train_len = int(np.round(X_s.shape[0]*.85))\n",
    "print(train_len)\n",
    "\n",
    "#assign training and test set\n",
    "X_train = X_s[:train_len] # everything before train_len\n",
    "y_train = y_s[:train_len]\n",
    "\n",
    "X_test = X_s[train_len:] # everything after train_len \n",
    "X_test = np.append(X_test, neg_testX, axis= 0) # append unused X neg class data\n",
    "\n",
    "y_test = y_s[train_len:]\n",
    "y_test = np.append(y_test, neg_testY, axis= 0) # append unused X neg class data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print('_________')\n",
    "\n",
    "\n",
    "# take validation set from training data\n",
    "# valid used to check quality of test set  \n",
    "valid_len = int(np.round(X_s.shape[0]*.1))\n",
    "print(valid_len)\n",
    "\n",
    "\n",
    "X_valid, X_train = X_train[:valid_len], X_train[valid_len:]\n",
    "y_valid, y_train = y_train[:valid_len], y_train[valid_len:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('_________')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "num_epochs = int(5e5) # num training loops\n",
    "batch_size = 1 # NOTE: ONLY SEEMS TO WORK W/ BATCH SIZE 1\n",
    "\n",
    "n_inputs = 8\n",
    "n_outputs = 2 # binary classifier\n",
    "num_nodes_l1 = 100 # 100 doesn't matter\n",
    "num_nodes_l2 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") #input values ––> specifying params of fed dict. \n",
    "ys = tf.placeholder(tf.int64, shape=(None), name=\"y\") #labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "hidden1 = tf.layers.dense(xs, num_nodes_l1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu) #first layer connected to input layer (placeholder)\n",
    "hidden2 = tf.layers.dense(hidden1, num_nodes_l2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "#Computes sparse softmax cross entropy between logits and labels.\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=ys, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "# cost = tf.reduce_mean(tf.square(outputs-ys)) # mse ... tf.losses.mean_squared_error(labels, predictions)\n",
    "optimizer = tf.train.AdamOptimizer( learning_rate )\n",
    "\n",
    "training_op = optimizer.minimize(loss) # optimize (reduce) mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says whether the targets are in the top K predictions.\n",
    "correct = tf.nn.in_top_k(logits, ys, 1)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # get starting accuracy val. \n",
    "    last_accuracy = accuracy.eval(feed_dict={xs: X_valid, ys: y_valid})\n",
    "    \n",
    "    for i in range(num_epochs):    \n",
    "        # select random subsets of data to train on (aka batches)\n",
    "        rnd_idx = np.random.permutation(len(X_train))[:batch_size]\n",
    "        X_batch = X_train[rnd_idx]\n",
    "        y_batch = y_train[rnd_idx]\n",
    "        # print out progress\n",
    "        if not(i%(10000)):\n",
    "    \n",
    "            # print epoch + accuracy val\n",
    "            print('epoch: ', i)\n",
    "            accuracy_val = accuracy.eval(feed_dict={xs: X_valid, ys: y_valid})\n",
    "            print(accuracy_val)\n",
    "            \n",
    "            \n",
    "#             print(y_valid[:10])\n",
    "#             logits_val = logits.eval(feed_dict={xs: X_valid, ys: y_valid})\n",
    "#             print(logits_val[:10])\n",
    "            \n",
    "            \n",
    "#             correct_val = correct.eval(feed_dict={xs: X_valid, ys: y_valid})\n",
    "#             print(correct_val)\n",
    "\n",
    "            \n",
    "            \n",
    "#             implement early stopping\n",
    "#             if (last_accuracy <= accuracy_val):\n",
    "#                 last_accuracy = accuracy_val \n",
    "#                 save_path = saver.save(sess, \"./my_model.ckpt\")\n",
    "#                 print(\"Model saved in path: %s\" % save_path)\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "            # save best model\n",
    "            if (accuracy_val > last_accuracy):\n",
    "                last_accuracy = accuracy_val \n",
    "                save_path = saver.save(sess, \"./my_model.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "            \n",
    "        sess.run(training_op, feed_dict={xs: X_batch, ys: y_batch}) #feed batch to optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #restore model from early stopping\n",
    "    saver.restore(sess, \"./my_model.ckpt\")\n",
    "    # generate predicted output values for y, test\n",
    "    pred_ys = sess.run(logits, feed_dict={xs:X_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:10])\n",
    "pred_ys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision // recall scores // F1 score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# get class prediction of each instance \n",
    "preds = []\n",
    "for i in range(len(pred_ys)):\n",
    "    preds.append(np.argmax(pred_ys[i], axis = 0))\n",
    "\n",
    "print(precision_score(y_test, preds))\n",
    "# 97.7% precise. Few False Positives\n",
    "\n",
    "print(recall_score(y_test, preds))\n",
    "# 93.6% accurate. Not a lot of False Negatives.\n",
    "\n",
    "print(f1_score(y_test, preds))\n",
    "# 95.6% f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, preds)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
